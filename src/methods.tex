\chapter{Materials and Methods}

\section{Dataset Description}
Two experimental dataset were available.
In the first study, 59 acute comatose patients were included between 7 days and 30 days after the coma onset (46 ± 16 years old; 21 females).
PET data were acquired in list mode during 90 min from the injection of an intravenous bolus of \fdg.
The second study, included 7 healthy subjects (25 ± 3 years old; all male) with injection of an intravenous bolus of \yohimbine.

Both dataset used the same exact following imaging protocol.
Simultaneously, an arterial time-of-flight MR (TOF-MRA)  in axial orientation, with a voxel size of 0.3$\times$0.3$\times$0.7 mm as well as a T1-weighted MRI in axial orientation, with isometric voxel size of 1mm were acquired.
Raw PET data were rebinned into 24-time frames (variable length frames : 8$\times$15 s, 3$\times$60 s, 5$\times$120 s, 1$\times$300 s, 7$\times$600 s) sinograms for dynamic reconstruction.
Reconstruction yielded a voxel size of 1.04$\times$1.04$\times$2.08 mm$^3$ in a matrix of 344$\times$344$\times$127 voxels.

In the \fdg  $\,$ study, AIF in the whole blood and plasma were measured from 26 arterial blood samples manually collected (with the following timing: every 5 s for the first minute, every 15 s until second minute, and at times 3, 5, 10, 20, 30, 45, 60, 75, 80, 85 and 90 minutes post-injection) and counted with a gamma counter.

In the \yohimbine $\,$study, 25 arterial blood samples were manually collected (with the following timing: every 5 s for the first minute, every 10 s until second minute, and at times 5, 10, 30, 45, 60, and 90 minutes post-injection).
The blood samples were counted with a gamma counter and were centrifuged and the extracted plasma was counted again to calculate the plasma fraction [TODO correct this part]


\section{Pre-processing}
For both studies, the T1-weighted image was registered to both the average PET image and to the TOF-MRA image using a affine registration method.
The two resulting affine transformation matrices were then combined to register the TOF-MRA directly to the PET.
Even though in the \fdg study, the patients were completely unconscious and the PET and MRI images were acquired simultaneously in the same session, this was still done out of an abundance of caution.
The T1-weighted image was used as a medium since it has common spatial features with both the other two modalities and directly registering TOF-MRA to the PET would be impractical due to the low spatial resolution of the PET and the limited axial FOV of the TOF-MRA images.

\section{Carotid Segmentation\label{sec:carotid}}
Figure~\ref{fig:seg_pipeline} shows the complete pipeline for the carotid segmentation.
Since vessels appear as hypersignal in TOF-MRA, a high-intensity thresholding technique can be used to extract the arteries from the image.
However, other tissues such as  brain lesion ---which were very common in the comatose dataset--- and venous structures may also appear as hypersignal and can interfere with the selection.
To exclude them, in a reference image, a cuboid volume of interest (VOI) was defined where the carotid arteries are most likely to appear (Step I).
The threshold value was calculated as the 1\% percentile of all non-zero voxels in the image and then it was applied to only to the voxels inside the VOI (Step II).
A 3D connectivity constraint was employed to the remaining voxels to extract all fully connected volumes and among those, the top 2 biggest were consider as the left and right internal carotid artery and extracted(Step III).

The reference image used was the standard MNI152 atlas, which was padded by 50\% more voxels in the inferior direction of the brain (negative Z in voxel-space) since the original atlas excludes the area below the brain which is of the interest for us.

The TOF-MRA image was then registered to the reference image using an affine registration technique and the obtained affine matrix was used to register and then apply the VOI to the TOF-MRA.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[
			node distance=1cm,
			auto,
			>=Stealth,
			mybox/.style={draw, rounded corners, rectangle, minimum width=3cm, minimum height=1cm, align=center}
		]
		\node[mybox] (input) {TOF-MRA};
		\node[mybox, right=of input] (cuboid) {I) Cuboid Mask\\Application};

		\node[mybox, right=of cuboid] (thresh) {II) Adaptive\\ Threshold};
		\node[mybox, below=of thresh] (growing) {III) Largest 2 Regions};
		\node[mybox, left=of growing] (dilation) {IV) Dilation};
		\node[mybox, below=of growing] (mask) {Carotid\\Mask};
		\node[mybox, below=of dilation] (bg_mask) {Background\\Mask};

		\draw[->] (input) -- (cuboid);
		\draw[->] (cuboid) -- (thresh);
		\draw[->] (thresh) -- (growing);
		\draw[->] (growing) -- (mask);
		\draw[->] (growing) -- (dilation);
		\draw[->] (dilation) -- (bg_mask);
	\end{tikzpicture}
	\caption{Carotid and background mask segmentation pipeline}
	\label{fig:seg_pipeline}
\end{figure}

\section{Partial Volume Correction}
\subsection{Geometric Transfer Matrix}
As we discussed before in \ref{TODO}, direct extraction of the radioactivity in the arteries is not practical due to PVC.
Geometric Transfer Matrix aims to account for this loss of signal by considering the observed TACs are linear combination of the true value and other effecting regions \cite{rousset1998correction}.

Here we define two regions, the carotid and the surrounding tissues (background).
A mask for extracting the activities of the latter was obtained by dilating the carotid mask by 5 pixels and subtracting the voxels corresponding to the carotid mask (Figure~\ref{fig:seg_pipeline}, Step IV).

\begin{equation}
	\underbrace{
		\begin{bmatrix}
			T_{c} \\
			T_{bg}
		\end{bmatrix}
	}_{\text{Observed}}
	=
	\underbrace{
		\begin{bmatrix}
			\omega_{c \rightarrow c}  & \omega_{bg \rightarrow c}  \\
			\omega_{c \rightarrow bg} & \omega_{bg \rightarrow bg}
		\end{bmatrix}
	}_{\text{GTM}}
	.
	\underbrace{
		\begin{bmatrix}
			T_{IF} \\
			T_{tissue}
		\end{bmatrix}
	}_{\text{Unknown}},
\end{equation}

where $\omega_{n \rightarrow m}$ are the spill-in and spill-over coefficient of region $n$ onto region $m$, which is obtained by convolving the binary mask of region $n$ with the system's point spread function and integrating the resulting intensity over region $m$, normalized by the total signal in region $m$.
where
\begin{equation}
	\omega_{n\to m} = \frac{\displaystyle \int_{\Omega_m} \bigl( h \ast \chi_n \bigr)(r)\,dr}{\displaystyle \int_{\Omega_m} \bigl( h \ast \chi_m \bigr)(r)\,dr},
\end{equation}
with \(\chi_n\) and \(\chi_m\) denoting the binary masks of regions \(n\) and \(m\), respectively, \(h\) the system's point spread function, and \(\Omega_m\) the spatial domain of region \(m\).

$T_{c}$ and $T_{bg}$ are respectively the observed carotid and background TACs and $T_{IF}$ and $T_{tissue}$ are the real unknown TACs of the carotid (the input function) and the background tissue.

By inverting the GTM, this system of equations can be easily solved and the "true" TAC in the artery and background be computed.
% However, through a combination of small size of the carotids and short time frames and exponential decay of the tracer
However, GTM along with other classical PVE methods usually fail to fully recover the lost signal as they are a simplification that does not consider the whole picture particularly accounting for the time-variant noise experienced in the signal.
This causes these methods to not only fail to correct the noise but end up amplifying them because of their assumptions.
The time-variant noise can be attributed to number of contributing factors, namely, the small size of the arteries, very short frame-times at the beginning of the scan where the changes in the input function are very rapid and rapid decay of the radiotracer which in all result in low-count statistic hence having higher noise.

However, the GTM being a low rank matrix makes the inversion sensitive to noise and biased on small regions such as the carotid \cite{zanotti2011image, boellaard2004effects}.

\subsection{Bayesian Geometric Transfer Matrix}
\subsubsection{Modelling}
% To overcome challenges posed to GTM method, we utilized a Bayesian framework that jointly estimates the input function, the tissue activity and the system noise\cite{irace2021bayesian}.
For each subject, $T_{IF}$ is modeled as a linear combination of a population mean and its principal components.
These components are derived by performing principal component analysis (PCA) on a set of arterial input functions (AIFs) collected from the population.
Specifically, for each subject, a subset of 20 random subjects is selected from the dataset—excluding the subject under study—to construct the PCA model.
The data are first zero-centered, and PCA is applied to extract the principal axes \(\phi_i(t)\) and their corresponding explained variances \(\lambda_i\).
Each axis is then scaled by \(\sqrt{\lambda_i}\) to yield components \(v_i(t)\) with distribution of \(\mathcal{N}(0,1)\). The input function is then modeled as:

\begin{equation}
	T_{IF}(t) = \mu(t) + \sum_{i=1}^p \theta_i\,v_i(t),
\end{equation}

with
\[
	v_i(t) = \sqrt{\lambda_i}\,\phi_i(t),
\]
where $p$ is the number of components, \(\mu(t)\) is the population mean AIF, \(\phi_i(t)\) are the principal axes obtained from PCA, \(\lambda_i\) are their explained variances, and \(v_i(t)\) are the scaled components. Due to this scaling, the weighting coefficients \(\theta_i\) will have a distribution of \(\sim \mathcal{N}(0,1)\).

Spectral Analysis (SA) has been proposed as a decomposition method for describing the tissue activity in dynamic PET.
This method produces a spectrum of kinetic components by modelling the TACs as a convolution of the input function with a impulse response function \cite{TODO}.

The impulse response function is considered as sum of multiple exponentials. Therefor the background TAC will be
\[
	T_{bg} = \sum_{i=1}^s \alpha_{i} \cdot T_{IF} \circledast e^{-\beta_{i} t}.
\]
Where $\circledast$ denotes the convolution operator, \(\alpha_i\) is the coefficient. and \(\beta_i\) is the frequency of the \(i\)th spectrum.

In model fitting using SA, an appropriate spectral range is chosen based on the radioisotope half-life and is then divided in to $s=100$ or $s=1000$ fixed frequencies ($\beta$).
The distinct peaks in the resulting spectrum are kept.
In our model ,t his approach would not be efficient. Instead we select the number of spectral peaks and let the model to tune the frequencies and the amplitudes (see section \ref{TODO}).

\subsubsection{Noise}

Accurately modelling the noise is nearly impossible as there are numerous sources of them.
Some sources of noise such as scattering effect, random events, and motion artifacts among others are corrected to some degree by the reconstruction program.
However the biggest contributor of noise is "low-count statistics" which is caused by short time frames at the begin of the scan and by the exponential decay of the radioisotope towards the end of the scan apparent by the low dose of the tracer injection.
This combined with the small size of the carotid introduces a massive challenge for recovering the lost signal.

Noise in raw PET counts is considered to be a Poisson distribution however after the reconstruction process it is widely assumed to be a Gaussian distribution \cite{TODO}. To account for the previously mentioned time-variant noise, weights are used to normalize the noise along all frames to a single statistic. We define the weights as
\[
	\omega_{i} = \frac{\Delta t_i}{c_i} e^{\frac{-t_{i} ln(2)}{T_{1/2}}}
\]
where \(\omega_i\) is the weight, \(\Delta t_i\) is the frame duration, and \(c_i\) is the net-true counts detected by the PET camera at the \(i\)th frame and  \(T_{1/2}\) is the half-life of the radioisotope.
However, \(c_i\) was substituted here with \(C_T(t_i)\), the total radioactivity concentration at the mid-time frame due to unavailability of these counts in our dataset.

The time-variant noise variances can be normalized as the weighted mean of the per frame variance.

\[
	\sigma^2= \frac{1}{N} \sum_{i=1}^{N} \omega_i \sigma_i^2.
\]


\subsubsection{Estimation}
Let us define  \(\mathcal{D}\) as the observed PET TAC, \( \Theta = (\theta_{1}, \dots,\theta_{p}, \alpha_{1}, \beta_{1}, \dots, \alpha_{s}, \beta_{s}) \) as the set of unknown parameters describing the system, and consider an unknown Gaussian noise present in the system. We seek to estimate the joint probability \(p(\Theta,\sigma^2\mid \mathcal{D})\) of the model parameters \(\Theta\) and noise level given the observed data \(\mathcal{D}\)

According to the Bayes rule:
\[
	p(\Theta,\sigma^2 \mid \mathcal{D}) \propto p(\mathcal{D} \mid \Theta,\sigma^2) \cdot \pi( \Theta ) \cdot \pi( \sigma^2)
\]
where  \(p(\Theta,\sigma^2 \mid \mathcal{D})\) is the posterior distribution, \(p(\mathcal{D} \mid \Theta,\sigma^2)\) is the likelihood, and $\pi(\Theta)$ and $\pi(\sigma^2)$ are the prior knowledge that we have on the set of parameters and the noise. Thus we can sample the posterior distribution by calculate the likelihood and having the priors.


We can derive the observed data from the GTM response of the model \ref{TODO}. For convenience, we define
\[
	\mathcal{T}(t) = \mathcal{G}(t;\Theta) =
	\mathcal{G}\left(
	\begin{bmatrix}
			T_{IF}(t;\theta_{1}, \dots, \theta_{p}) \\
			T_{tissue}(t;\alpha_{1}, \beta_{1}, \dots)
		\end{bmatrix}\right)
\]
where $\mathcal{G}$ is the GTM model and $\mathcal{T}$ is the perceived activity based on the GTM model (effected by PVE). Since we considered the noise to be Gaussian, the likelihood would be

\[
	p(\mathcal{D} \mid \Theta,\sigma^2) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left( -\frac{\omega_i(\mathcal{D}(t_i) - \mathcal{T}(t_i))^2}{2\sigma^2} \right).
\]

The prior of parameters can be expanded as

\[
	\pi(\Theta) = \prod_{i=1}^p \pi(\theta_i)  \prod_{j=1}^s \pi(\alpha_j) \pi(\beta_j).
\]
As mentioned before, the PCA weighting coefficients have a normal distribution of $\mathcal{N}(0,1)$ which is also used as their prior knowledge.
The prior for the frequency and amplitude in SA was chosen as a reasonable uniform distribution range.
\[
	\alpha_i,\beta_i \sim \mathcal{U}( u_{\text{min}} , u_{\text{max}} )
\]

The prior distribution for the noise variance, $\pi(\sigma^2)$, is specified as an inverse-gamma distribution with hyperparameters $a_0$ and $b_0$ since inverse-gamma is the prior conjugate for the variance of a normal distribution
\[
	\sigma^2 \sim \Gamma^{-1}(a_0,b_0)
\]

In this work, the hyperparameters are selected so that $\pi(\sigma^2)$ is centered around an empirical estimate of the TAC variance, computed as the weighted root mean squared error between the observed carotid TAC and the mean AIF.

\[
	\mathbb{E}[X] = \frac{1}{N} \sum_{i=1}^{N} (T_c(t_i) - \mu(t_i))^2
\]
Thus by choosing a Coefficient of Variation (CV), we will have
\[
	a_0 = 2 + \frac{1}{\mathrm{CV}^2}\, , \, b_0 = (a_0 - 1) \, \mathbb{E}[X]
\]
\subsubsection{Sampling}

Evaluating the posterior distribution \ref{TODO} directly is not feasible due to its complexity and lack of a closed-form solution.
Thus we utilize a Monte-Carlo sampler to estimate the posterior distribution by taking sufficient random samples.
In this work, we utilize a Markov Chain Monte-Carlo with a hybrid Metropolis-within-Gibbs sampling method.

The Gibbs sampler allows for separately drawing sample for each parameter one by one based on its univariate posterior conditional distribution $p(\Theta_i \mid \mathcal{D}, \Theta_{-i}, \sigma^2)$ for each $\Theta_i$ where $\Theta_{-i}$ is the parameter vector except $\Theta_i$ and $p(\sigma^2 \mid \mathcal{D},\Theta)$ for the $\sigma^2$.

By iteratively doing this, Gibbs sampling results in the desired multivariate conditional posterior distribution $p(\Theta,\sigma^2 \mid \mathcal{D})$.

The exploration of the parameters $\Theta$ is done using the Metropolis-Hasting algorithm.
In this algorithm, a new parameter is proposed based on slightly changing the previous sample.
For example at the $m$th iteration in the chain, a new proposal for $\Theta_{i}^{(m)}$ is given as $\Theta_{i}^\prime = \Theta_{i}^{(m)} + \varepsilon_{i} \cdot b$, where $\varepsilon_{i}$ is the scaling factor or step-size and $b$ is a Brownian motion.
The proposal is either accepted and is kept as the new sample or rejected and the parameter stays unchanged.
The acceptance probability is given by
\[
	min\left(1,\frac{p(\Theta_i^\prime \mid \mathcal{D}, \Theta_{-i}, \sigma^2)}{p(\Theta_i^{(m)}\mid \mathcal{D}, \Theta_{-i}, \sigma^2)}\right)
\]

By choosing inverse-gamma for the noise prior which is conjugate prior, the posterior distribution is also a inverse-gamma distribution.

\[
	p(\sigma^2 \mid \mathcal{D},\Theta) \sim \Gamma^{-1}(a, b)
\]
where
\[
	a=a_0 + \frac{N}{2} \quad, b= b_0 + \sum_{i=0}^N \omega_i(\mathcal{D}(t_i) - \mathcal{T}(t_i))^2.
\]
Since we have a closed-form expression for the posterior distribution of the noise variance, we can just simply draw samples without the Metropolis-Hasting acceptance/rejection method.

To ensure efficient exploration of the parameter space, each parameter \( k \) is assigned its own proposal step size \( \epsilon_k \).
During the burn-in phase, these step sizes are adapted in blocks of \( L = 50 \) Metropolis–Hastings updates by monitoring the empirical acceptance rate for each parameter.
If the acceptance rate for a parameter exceeds 0.5, its step size is increased by an arbitrary 10\% (\( \epsilon_k \leftarrow 1.1\,\epsilon_k \)); otherwise, it is decreased by 10\% (\( \epsilon_k \leftarrow 0.9\,\epsilon_k \)).
This adaptive tuning continues until the end of the burn-in period, after which all step sizes are fixed and subsequent samples are retained.

\subsubsection{Inference}
After sufficient sampling, we employ a modified Maximum a Posteriori (MAP) method by calculating the average parameters of the top 0.1\% samples with the highest posterior probability and considering it as the solution.



\section{Evaluation}
\subsection{IF Curves}
The performance of the proposed IDIF estimation was first evaluated by computing the mean absolute error (MAE) between the cumulative area under the curve (cAUC) of the estimated IDIF and the \textit{ground true} AIF. cAUC was considered to be a more suitable metric since it provides an integrated measure of tracer exposure over time and is less sensitive to local fluctuations or noise in the curve compared to the directly comparing the TACs.
\begin{equation}
	\textrm{cAUC}(t) =  \int_{0}^{t} IF(\tau) \, d\tau,
\end{equation}
where \(IF\) is the input function.

\subsection{Quantification}
However, because the cAUC error does not fully capture the impact of IDIF deviations on kinetic parameters, absolute quantification was also performed to evaluate the performance of the estimated IDIF against the gold standard AIF.
This was achieved by utilizing an irreversible two-tissue compartment model (2TCM) via non-linear fitting with the \texttt{fitk3} program from the TPCCLIB library developed at the Turku PET Centre \cite{oikonen2018tpcclib}—applying the model fitting once with the IDIF and once with the AIF as the input function.

The brain was segmented into regions of interest (ROI) based on the Hammersmith brain atlas \cite{hammers2003three}, and TACs were generated by averaging voxels over each ROI at every time point.
The regional influx rate (\(K_i\)) was then calculated, from which the corresponding \(\mrglu\) values were derived.

The mean absolute percentage error (MAPE) of the \(\textrm{MR}_{glu}\) in each ROI was calculated and then averaged across the entire dataset:
\begin{equation}
	\text{Average MAPE}(\mrglu)= \frac{100\%}{N} \sum_{i=1}^{N} \left( \frac{1}{N_{\text{ROI}}} \sum_{j=1}^{N_{\text{ROI}}} \left| \frac{\textrm{MR}_{\textrm{glu},ij}^{\textrm{IDIF}} - \textrm{MR}_{\textrm{glu},ij}^{\textrm{AIF}}}{\textrm{MR}_{\textrm{glu},ij}^{\textrm{AIF}}} \right| \right),
\end{equation}
where $N$ is the number of subjects.

Additionally, linear least-squares regression was performed between the regional \(\mrglu\) obtained by quantification with using AIF and IDIF for each subject. The coefficient of determination (\(R^2\)) and the regression slope (\(S\)) were obtained for each subject. The mean absolute errors of these metrics across the dataset are given by
\begin{equation}
	\text{MAE}(R^2) = \frac{1}{N} \sum_{i=1}^{N} \left| R^2_i - 1 \right|
\end{equation}
and
\begin{equation}
	\text{MAE}(S) = \frac{1}{N} \sum_{i=1}^{N} \left| S_i - 1 \right|,
\end{equation}
where $N$ is the number of subjects and \(R^2_i\) and \(S_i\) denote the coefficient of determination and the regression slope for subject \(i\), respectively.

\section{Simulation}
PET simulations are an integral part of the validation of statistical and analytical PET methods as they have the advantage of knowing the exact ground truth which is not always available or might be effected by human or instrument malfunction.
In the previous section, we considered the AIF to be the gold standard and the ground truth and the evaluation was done by comparing the method to it.
But since the AIF is taken and analysed manually and involves multiple devices and processes operated by different personnels (nurses and chemists) at different steps, there is a large possibility for mistakes.

For this reason, as a complementary validation step to the experimental datasets, simulations were conducted and the method will be evaluated on them as well.

PET-SORTEO is a realistic Monte-Carlo PET simulation platform
